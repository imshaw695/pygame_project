{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 64-bit ('base': conda)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Task_template_name_module.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "ccecdff9ca714e38c2a39eaceb97a71eff69a630c8c613629541139f68212202"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuWeGn43yeHk"
      },
      "source": [
        "# Module 4 Guidance\n",
        "\n",
        "This notebook is a template for module 4b and 4c, which will be tested in Google Colab, your code needs to run there.\n",
        "The structure has been provided to improve consistency and make it easier for markers to understand your code but still give students the flexibility to be creative.  You need to populate the required functions to solve this problem.  All dependencies should be documented in the next cell.\n",
        "\n",
        "You can:\n",
        "    add further cells or text blocks to extend or further explain your solution\n",
        "    add further functions\n",
        "\n",
        "Dont:\n",
        "    rename functions\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USzvedjfyeHp"
      },
      "source": [
        "# Fixed dependencies - do not remove or change.\n",
        "import pytest\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive/')\n",
        "# Import your dependencies\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9Ru2FFyyeHp"
      },
      "source": [
        "# Import data\n",
        "\n",
        "def import_local_data(file_path):\n",
        "    \"\"\"This function needs to import the data file into collab and return a pandas dataframe\n",
        "    \"\"\"\n",
        "    raw_df = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "    return raw_df"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyvrH3ezyeHq"
      },
      "source": [
        "# this_directory = os.path.abspath(os.path.dirname(__file__))\n",
        "# Importing the dataset\n",
        "# local_file_path = os.path.join(this_directory,'breast-cancer.csv')\n",
        "local_file_path = 'breast-cancer.csv'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C_hpKUeyeHq"
      },
      "source": [
        "# Dont change\n",
        "raw_data = import_local_data(local_file_path)\n",
        "print(raw_data)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       age menopause tumor-size inv-nodes node-caps  deg-malig breast  \\\n0    40-49   premeno      15-19       0-2       yes          3  right   \n1    50-59      ge40      15-19       0-2        no          1  right   \n2    50-59      ge40      35-39       0-2        no          2   left   \n3    40-49   premeno      35-39       0-2       yes          3  right   \n4    40-49   premeno      30-34    03-May       yes          2   left   \n..     ...       ...        ...       ...       ...        ...    ...   \n281  50-59      ge40      30-34    06-Aug       yes          2   left   \n282  50-59   premeno      25-29    03-May       yes          2   left   \n283  30-39   premeno      30-34    06-Aug       yes          2  right   \n284  50-59   premeno      15-19       0-2        no          2  right   \n285  50-59      ge40      40-44       0-2        no          3   left   \n\n    breast-quad irradiat                 Class  \n0       left_up       no     recurrence-events  \n1       central       no  no-recurrence-events  \n2      left_low       no     recurrence-events  \n3      left_low      yes  no-recurrence-events  \n4      right_up       no     recurrence-events  \n..          ...      ...                   ...  \n281    left_low       no  no-recurrence-events  \n282    left_low      yes  no-recurrence-events  \n283    right_up       no  no-recurrence-events  \n284    left_low       no  no-recurrence-events  \n285    right_up       no  no-recurrence-events  \n\n[286 rows x 10 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2b7OBPvyeHq"
      },
      "source": [
        "### Conduct exploratory data analysis and explain your key findings - Examine the data, explain its key features and what they look like.  Highlight any fields that are anomalous."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71bhS-W_yeHq"
      },
      "source": [
        "# Age, tumor size and inv nodes are in ranges rather than whole numbers. Inv nodes seems to have some formatting errors, changing some to dates."
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diWKBUsryeHr"
      },
      "source": [
        "# The node-caps variable has a value of '?' 8 times, which I will need to either replace or ignore the rows altogether. "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPf2HMSOyeHr"
      },
      "source": [
        "# Other variables are categorical and should be easy to work with. There are significantly more 'no-recurrence-events' than 'recurrence', which may cause problems"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8u_fMf7yeHr"
      },
      "source": [
        "Create any data pre-processing that you will conduct on seen and unseen data.  Regardless of the model you use, this dataframe must contain only numeric features and have a strategy for any expected missing values. Any objects can that are needed to handle the test data that are dependent on the training data can be stored in the model class.  You are recommended to use sklearn Pipelines or similar functionality to ensure reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpWY9_zXyeHr"
      },
      "source": [
        "# Split your data so that you can test the effectiveness of your model\n",
        "x = raw_data.iloc[:, :-1].values\n",
        "y = raw_data.iloc[:, -1].values\n",
        "\n",
        "def preprocess_training_data(self, x):\n",
        "    \"\"\"\n",
        "    This function should process the training data and store any features required in the class\n",
        "    I need to turn \n",
        "    \"\"\"\n",
        "    # This for loop is replacing the age ranges with an average of the high and low values of the range\n",
        "    for column_index,column in enumerate(x[:,0]):\n",
        "        low,high = column.split('-')\n",
        "        number = (int(low) + int(high))/2\n",
        "        x[column_index,0] = number\n",
        "\n",
        "    # The LabelEncoder here is turning the breast and irradiat variables into 0's and 1's\n",
        "    x[:,6] = le.fit_transform(x[:,6])\n",
        "    x[:,8] = le.fit_transform(x[:,8])\n",
        "\n",
        "    # Here I will attempt to fix index 2 and 3, so that they no longer have months but the original values, then take the average as with age (index 0)      \n",
        "    fixed = True\n",
        "\n",
        "    if fixed == True:  \n",
        "        for column_index,column in enumerate(x[:,2]):\n",
        "            if 'May' in column:\n",
        "                fixed_column = column.replace('Oct','10')\n",
        "                x[column_index,2] = fixed_column\n",
        "            if 'Sep' in column:\n",
        "                fixed_column = column.replace('Sep','9')\n",
        "                x[column_index,2] = fixed_column\n",
        "            if 'Oct' in column:\n",
        "                fixed_column = column.replace('Oct','10')\n",
        "                x[column_index,2] = fixed_column\n",
        "        for column_index,column in enumerate(x[:,3]):\n",
        "            if 'Nov' in column:\n",
        "                fixed_column = column.replace('Nov','11')\n",
        "                x[column_index,3] = fixed_column\n",
        "            if 'May' in column:\n",
        "                fixed_column = column.replace('May','5')\n",
        "                x[column_index,3] = fixed_column\n",
        "            if 'Aug' in column:\n",
        "                fixed_column = column.replace('Aug','9')\n",
        "                x[column_index,3] = fixed_column\n",
        "            if 'Dec' in column:\n",
        "                fixed_column = column.replace('Dec','12')\n",
        "                x[column_index,3] = fixed_column\n",
        "        for column_index,column in enumerate(x[:,2]):\n",
        "            low,high = column.split('-')\n",
        "            number = (int(low) + int(high))/2\n",
        "            x[column_index,2] = number\n",
        "        for column_index,column in enumerate(x[:,3]):\n",
        "            low,high = column.split('-')\n",
        "            number = (int(low) + int(high))/2\n",
        "            x[column_index,3] = number\n",
        "\n",
        "    # Here I am using OneHotEncoder to turn the remaining categories into their own binary variables\n",
        "    from sklearn.compose import ColumnTransformer\n",
        "    from sklearn.preprocessing import OneHotEncoder\n",
        "    # For index 4, I should really set yes to 1, no to 0, and ? to -1 rather than using OneHotEncoder\n",
        "    \n",
        "    ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1,4,6,7])], remainder='passthrough')\n",
        "    x = np.array(ct.fit_transform(x))\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    sc = StandardScaler()\n",
        "    x = sc.fit_transform(x)\n",
        "    processed_df = x\n",
        "\n",
        "    return processed_df\n",
        "\n",
        "x_processed = my_model.preprocess_training_data(x)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train_processed, x_test_processed, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 1)\n",
        "# was not sure where to encode the dependent variables, so I did it here\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_test = le.fit_transform(y_test)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'raw_data' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-4-d62a8a54c12f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Split your data so that you can test the effectiveness of your model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpreprocess_training_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'raw_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNrlNdvuyeHs"
      },
      "source": [
        "# Populate preprocess_training_data and preprocess_test_data to preprocess data.\n",
        "# You must process test and train separately so your model does not accidently gain information that a model wouldnt have in reality and therefore get better predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbeqAOjyyeHs"
      },
      "source": [
        "class Module4_Model:\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        \n",
        "    def preprocess_training_data(self, training_df):\n",
        "        \"\"\"\n",
        "        This function should process the training data and store any features required in the class\n",
        "        I need to turn \n",
        "        \"\"\"\n",
        "        # This for loop is replacing the age ranges with an average of the high and low values of the range\n",
        "        for column_index,column in enumerate(training_df[:,0]):\n",
        "            low,high = column.split('-')\n",
        "            number = (int(low) + int(high))/2\n",
        "            training_df[column_index,0] = number\n",
        "\n",
        "        # The LabelEncoder here is turning the breast and irradiat variables into 0's and 1's\n",
        "        training_df[:,6] = le.fit_transform(training_df[:,6])\n",
        "        training_df[:,8] = le.fit_transform(training_df[:,8])\n",
        "\n",
        "        # Here I will attempt to fix index 2 and 3, so that they no longer have months but the original values, then take the average as with age (index 0)      \n",
        "        fixed = True\n",
        "\n",
        "        if fixed == True:  \n",
        "            for column_index,column in enumerate(training_df[:,2]):\n",
        "                if 'May' in column:\n",
        "                    fixed_column = column.replace('Oct','10')\n",
        "                    training_df[column_index,2] = fixed_column\n",
        "                if 'Sep' in column:\n",
        "                    fixed_column = column.replace('Sep','9')\n",
        "                    training_df[column_index,2] = fixed_column\n",
        "                if 'Oct' in column:\n",
        "                    fixed_column = column.replace('Oct','10')\n",
        "                    training_df[column_index,2] = fixed_column\n",
        "            for column_index,column in enumerate(training_df[:,3]):\n",
        "                if 'Nov' in column:\n",
        "                    fixed_column = column.replace('Nov','11')\n",
        "                    training_df[column_index,3] = fixed_column\n",
        "                if 'May' in column:\n",
        "                    fixed_column = column.replace('May','5')\n",
        "                    training_df[column_index,3] = fixed_column\n",
        "                if 'Aug' in column:\n",
        "                    fixed_column = column.replace('Aug','9')\n",
        "                    training_df[column_index,3] = fixed_column\n",
        "                if 'Dec' in column:\n",
        "                    fixed_column = column.replace('Dec','12')\n",
        "                    training_df[column_index,3] = fixed_column\n",
        "            for column_index,column in enumerate(training_df[:,2]):\n",
        "                low,high = column.split('-')\n",
        "                number = (int(low) + int(high))/2\n",
        "                training_df[column_index,2] = number\n",
        "            for column_index,column in enumerate(training_df[:,3]):\n",
        "                low,high = column.split('-')\n",
        "                number = (int(low) + int(high))/2\n",
        "                training_df[column_index,3] = number\n",
        "\n",
        "        # Here I am using OneHotEncoder to turn the remaining categories into their own binary variables\n",
        "        from sklearn.compose import ColumnTransformer\n",
        "        from sklearn.preprocessing import OneHotEncoder\n",
        "        # For index 4, I should really set yes to 1, no to 0, and ? to -1 rather than using OneHotEncoder\n",
        "        \n",
        "        ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1,4,6,7])], remainder='passthrough')\n",
        "        training_df = np.array(ct.fit_transform(training_df))\n",
        "        from sklearn.preprocessing import StandardScaler\n",
        "        sc = StandardScaler()\n",
        "        training_df = sc.fit_transform(training_df)\n",
        "        processed_df = training_df\n",
        "\n",
        "        return processed_df\n",
        "\n",
        "    def preprocess_test_data(self, test_df):\n",
        "\n",
        "        \"\"\"\n",
        "        This function should process the training data and store any features required in the class\n",
        "        I need to turn \n",
        "        \"\"\"\n",
        "        # This for loop is replacing the age ranges with an average of the high and low values of the range\n",
        "        for column_index,column in enumerate(test_df[:,0]):\n",
        "            low,high = column.split('-')\n",
        "            number = (int(low) + int(high))/2\n",
        "            test_df[column_index,0] = number\n",
        "\n",
        "        # The LabelEncoder here is turning the breast and irradiat variables into 0's and 1's\n",
        "        test_df[:,6] = le.fit_transform(test_df[:,6])\n",
        "        test_df[:,8] = le.fit_transform(test_df[:,8])\n",
        "\n",
        "        # Here I will attempt to fix index 2 and 3, so that they no longer have months but the original values, then take the average as with age (index 0)      \n",
        "        fixed = True\n",
        "\n",
        "        if fixed == True:  \n",
        "            for column_index,column in enumerate(test_df[:,2]):\n",
        "                if 'May' in column:\n",
        "                    fixed_column = column.replace('Oct','10')\n",
        "                    test_df[column_index,2] = fixed_column\n",
        "                if 'Sep' in column:\n",
        "                    fixed_column = column.replace('Sep','9')\n",
        "                    test_df[column_index,2] = fixed_column\n",
        "                if 'Oct' in column:\n",
        "                    fixed_column = column.replace('Oct','10')\n",
        "                    test_df[column_index,2] = fixed_column\n",
        "            for column_index,column in enumerate(test_df[:,3]):\n",
        "                if 'Nov' in column:\n",
        "                    fixed_column = column.replace('Nov','11')\n",
        "                    test_df[column_index,3] = fixed_column\n",
        "                if 'May' in column:\n",
        "                    fixed_column = column.replace('May','5')\n",
        "                    test_df[column_index,3] = fixed_column\n",
        "                if 'Aug' in column:\n",
        "                    fixed_column = column.replace('Aug','9')\n",
        "                    test_df[column_index,3] = fixed_column\n",
        "                if 'Dec' in column:\n",
        "                    fixed_column = column.replace('Dec','12')\n",
        "                    test_df[column_index,3] = fixed_column\n",
        "            for column_index,column in enumerate(test_df[:,2]):\n",
        "                low,high = column.split('-')\n",
        "                number = (int(low) + int(high))/2\n",
        "                test_df[column_index,2] = number\n",
        "            for column_index,column in enumerate(test_df[:,3]):\n",
        "                low,high = column.split('-')\n",
        "                number = (int(low) + int(high))/2\n",
        "                test_df[column_index,3] = number\n",
        "\n",
        "        # Here I am using OneHotEncoder to turn the remaining categories into their own binary variables\n",
        "        from sklearn.compose import ColumnTransformer\n",
        "        from sklearn.preprocessing import OneHotEncoder\n",
        "        # For index 4, I should really set yes to 1, no to 0, and ? to -1 rather than using OneHotEncoder\n",
        "        \n",
        "        ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1,4,6,7])], remainder='passthrough')\n",
        "        test_df = np.array(ct.fit_transform(test_df))\n",
        "        from sklearn.preprocessing import StandardScaler\n",
        "        sc = StandardScaler()\n",
        "        test_df = sc.fit_transform(test_df)\n",
        "        processed_df = test_df\n",
        "\n",
        "        return processed_df\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN0_zDPFyeHt"
      },
      "source": [
        "# Dont change\n",
        "my_model = Module4_Model()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mK9beCnyeHt"
      },
      "source": [
        "# Dont change\n",
        "# x_train_processed = my_model.preprocess_training_data(x_train)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'float' object has no attribute 'split'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-15-5830613090bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Dont change\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx_train_processed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess_training_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-10-d15d774c2a09>\u001b[0m in \u001b[0;36mpreprocess_training_data\u001b[1;34m(self, training_df)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m# This for loop is replacing the age ranges with an average of the high and low values of the range\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcolumn_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mlow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhigh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mnumber\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhigh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mtraining_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumber\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'split'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEyNp57WyeHt"
      },
      "source": [
        "# Create a model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnb7YrOxyeHv"
      },
      "source": [
        "ann = tf.keras.models.Sequential()\n",
        "\n",
        "ann.add(tf.keras.layers.Dense(units=6, activation=\"relu\"))\n",
        "\n",
        "ann.add(tf.keras.layers.Dense(units=6, activation=\"relu\"))\n",
        "\n",
        "ann.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "ann.compile(optimizer='adam' , loss='binary_crossentropy' , metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiLG-6EByeHv"
      },
      "source": [
        "# Dont change\n",
        "# x_test_processed = my_model.preprocess_test_data(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyd6959hyeHx"
      },
      "source": [
        "# Train your model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2MB6-FPyeHx"
      },
      "source": [
        "history = ann.fit(x_train_processed, y_train, epochs=15)\n",
        "model_accuracy = history.history['accuracy'][-1]\n",
        "model_loss = history.history['loss'][-1]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHNTGicRyeHx"
      },
      "source": [
        "# use your model to make a prediction on unseen data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVXlimZryeHy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHHnwqGHyeHy"
      },
      "source": [
        "# Asssess the accuracy of your model and explain your key findings\n",
        "loss, accuracy = ann.evaluate(x_test_processed, y_test)\n",
        "\n",
        "print(accuracy)\n",
        "print()\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_2tLl3OyeHy"
      },
      "source": [
        "### Unit tests:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5w1HNNHyeHy"
      },
      "source": [
        "#### Checking training and test data for null values. This will work for both pd dataframes and np arrays, and ensures no null values exist."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0h-fwWRyeHz"
      },
      "source": [
        "def test_no_nulls(data):\n",
        "    \"\"\" Assert no null values within pd dataframe or np array \"\"\"\n",
        "    \n",
        "    # if data is numpy array, handle accordingly\n",
        "    if isinstance(data, (np.ndarray)):\n",
        "        assert not np.isnan(np.min(data))\n",
        "    \n",
        "    # if not np array, assume data is pandas dataframe\n",
        "    else:\n",
        "        assert data.isna().sum().sum() == 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIjldycEyeHz"
      },
      "source": [
        "# run null data unit test on both training and test data\n",
        "test_no_nulls(x_train_processed)\n",
        "test_no_nulls(x_test_processed)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}